{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VM Placement Optimization\n",
    "\n",
    "> **Student:** Jules Decaestecker\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project focuses on optimizing the placement of Virtual Machines (VMs) onto clusters (or servers) while minimizing the number of clusters used. The problem involves various constraints related to VM requirements, cluster capacities, and additional placement rules.\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "### **Input:**\n",
    "\n",
    "- A set of VMs, each with specific requirements:\n",
    "  - Number of vCPUs\n",
    "  - RAM (GB)\n",
    "  - Disk space (GB)\n",
    "- A set of clusters with given capacities:\n",
    "  - Number of vCPUs\n",
    "  - RAM (GB)\n",
    "  - Disk space (GB)\n",
    "\n",
    "### **Output:**\n",
    "\n",
    "- Minimized number of clusters used.\n",
    "\n",
    "## Problem Variants & Constraints\n",
    "\n",
    "We consider multiple variants of the VM placement problem:\n",
    "\n",
    "1. **Affinity and Anti-affinity Rules:**\n",
    "\n",
    "   - Some VMs should be placed together (affinity).\n",
    "   - Some VMs must not share the same cluster (anti-affinity).\n",
    "   - Only anti-affinities between specific VM pairs are considered.\n",
    "\n",
    "2. **Cluster Characteristics:**\n",
    "\n",
    "   - Clusters can be partially occupied or initially empty.\n",
    "   - Clusters may have heterogeneous capacities (multiple types of servers).\n",
    "\n",
    "3. **Splitting of VMs:**\n",
    "   - VMs may be split across multiple clusters.\n",
    "4. **VM Families and Criticality Levels:**\n",
    "   - VMs belong to families, each with a criticality level (1, 2, or 3).\n",
    "   - Levels 1 & 2 or levels 2 & 3 can be together, but not levels 1 & 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.optimize import milp, LinearConstraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate data\n",
    "\n",
    "Create VMs with random vcpu, memory and disk requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM ID\tVM Name               \tvCPU\tMemory(GB)\tDisk Space(GB)\n",
      "0\tWobblyPenguin-505     \t4\t22\t\t24\t\t\n",
      "1\tQuirkyPancake-663     \t3\t11\t\t4\t\t\n",
      "2\tSoggyMuffin-509       \t8\t9\t\t11\t\t\n",
      "3\tZestyPancake-680      \t7\t10\t\t6\t\t\n",
      "4\tBouncyOctopus-345     \t5\t22\t\t16\t\t\n",
      "5\tSpicyToaster-948      \t3\t10\t\t12\t\t\n",
      "6\tSoggyBanana-733       \t3\t21\t\t26\t\t\n",
      "7\tSpicyNoodle-992       \t4\t5\t\t22\t\t\n",
      "8\tJollyMuffin-500       \t3\t11\t\t18\t\t\n",
      "9\tGrumpyBanana-870      \t4\t18\t\t26\t\t\n"
     ]
    }
   ],
   "source": [
    "def generate_vm_name():\n",
    "    adjectives = [\"Wobbly\", \"Fluffy\", \"Spicy\", \"Grumpy\",\n",
    "                  \"Sneaky\", \"Jolly\", \"Zesty\", \"Quirky\", \"Bouncy\", \"Soggy\"]\n",
    "    nouns = [\"Penguin\", \"Toaster\", \"Banana\", \"Octopus\", \"Pancake\",\n",
    "             \"Noodle\", \"Cactus\", \"Sasquatch\", \"Pickle\", \"Muffin\"]\n",
    "    number = random.randint(1, 999)\n",
    "    return f\"{random.choice(adjectives)}{random.choice(nouns)}-{number}\"\n",
    "\n",
    "\n",
    "def generate_vm(n: int, max_vcpu=8, max_memory=24, max_disk_space=32, criticity=False):\n",
    "    \"\"\"\"\n",
    "    Generate a list of VMs using random features\n",
    "\n",
    "    Input:\n",
    "    n: int - number of VMs to generate\n",
    "    \"\"\"\n",
    "    res = []\n",
    "\n",
    "    for i in range(n):\n",
    "        # generate VM name\n",
    "        vm_name = generate_vm_name()\n",
    "        # generate vCPU\n",
    "        vcpu = random.randint(1, max_vcpu)\n",
    "        # generate Memory (GB)\n",
    "        memory = random.randint(1, max_memory)\n",
    "        # generate Disk Space (GB)\n",
    "        disk_space = random.randint(1, max_disk_space)\n",
    "        # generate criticity between 1 and 3\n",
    "        if criticity:\n",
    "            criticity = random.randint(1, 3)\n",
    "            res.append([vm_name, vcpu, memory, disk_space, criticity])\n",
    "        else:\n",
    "            res.append([vm_name, vcpu, memory, disk_space])\n",
    "    # type cast to numpy array for better performance\n",
    "    return np.array(res)\n",
    "\n",
    "def show_vms(vms: list):\n",
    "    max_len_name = max([len(vm[0]) for vm in vms]) + 5\n",
    "    print(f\"VM ID\\tVM Name{' '*(max_len_name-7)}\\tvCPU\\tMemory(GB)\\tDisk Space(GB){'\\tCriticity' if len(vms[0]) == 5 else ''}\")\n",
    "    for i, vm in enumerate(vms):\n",
    "        print(f\"{i}\\t{vm[0]+ ' '*(max_len_name - len(vm[0]))}\\t{vm[1]}\\t{vm[2]}\\t\\t{vm[3]}\\t\\t{vm[4] if len(vm) == 5 else ''}\")\n",
    "\n",
    "vms = generate_vm(10)\n",
    "show_vms(vms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster ID\tCluster Name             \tvCPU\tMemory(GB)\tDisk Space(GB)\n",
      "0\t\tus-west1-Epsilon-698     \t4\t57\t\t117\n",
      "1\t\tus-west2-Iota-294        \t2\t52\t\t120\n",
      "2\t\tus-west3-Eta-76          \t52\t32\t\t37\n",
      "3\t\tus-west2-Delta-987       \t52\t27\t\t8\n",
      "4\t\tus-west1-Epsilon-543     \t12\t60\t\t8\n",
      "5\t\tus-west2-Theta-546       \t20\t12\t\t74\n",
      "6\t\tus-west3-Alpha-908       \t43\t34\t\t37\n",
      "7\t\tus-west3-Gamma-927       \t25\t10\t\t104\n",
      "8\t\tus-east2-Beta-405        \t57\t54\t\t60\n",
      "9\t\tus-east2-Theta-519       \t26\t58\t\t62\n"
     ]
    }
   ],
   "source": [
    "def generate_cluster_name():\n",
    "    zones = [\"us-west1\", \"us-west2\", \"us-west3\", \"us-east1\", \"us-east2\", \"us-east3\"]\n",
    "    names = [\"Alpha\", \"Beta\", \"Gamma\", \"Delta\", \"Epsilon\", \"Zeta\", \"Eta\", \"Theta\", \"Iota\", \"Kappa\"]\n",
    "    number = random.randint(1, 999)\n",
    "    return f\"{random.choice(zones)}-{random.choice(names)}-{number}\"\n",
    "\n",
    "def generate_cluster(n: int, max_vcpu=64, max_memory=64, max_disk_space=128, random_=True) -> list:\n",
    "    res = []\n",
    "\n",
    "    for i in range(n):\n",
    "        # generate cluster name\n",
    "        cluster_name = generate_cluster_name()\n",
    "        \n",
    "        # generate vCPU, Memory, Disk Space\n",
    "        if random_:\n",
    "            vcpu = random.randint(1, max_vcpu)\n",
    "            memory = random.randint(1, max_memory)\n",
    "            disk_space = random.randint(1, max_disk_space)\n",
    "        else:\n",
    "            vcpu = max_vcpu\n",
    "            memory = max_memory\n",
    "            disk_space = max_disk_space\n",
    "        \n",
    "        res.append([cluster_name, vcpu, memory, disk_space])\n",
    "    return np.array(res)\n",
    "\n",
    "def show_clusters(clusters: list):\n",
    "    max_len_name = max([len(cluster[0]) for cluster in clusters]) + 5\n",
    "    print(f\"Cluster ID\\tCluster Name{' '*(max_len_name-12)}\\tvCPU\\tMemory(GB)\\tDisk Space(GB)\")\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        print(f\"{i}\\t\\t{cluster[0]+ ' '*(max_len_name - len(cluster[0]))}\\t{cluster[1]}\\t{cluster[2]}\\t\\t{cluster[3]}\")\n",
    "\n",
    "clusters = generate_cluster(10)\n",
    "show_clusters(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "\n",
    "### Decision Variables\n",
    "\n",
    "- $x_{ij} \\in \\{0, 1\\}$: Binary variable indicating whether VM $i$ is placed on cluster $j$.\n",
    "- $y_i \\in \\{0, 1\\}$: Binary variable indicating whether VM $i$ is used.\n",
    "\n",
    "### Objective Function\n",
    "\n",
    "- **Minimize** the number of cluster used: $\\sum_{i=1}^{n} y_i$\n",
    "\n",
    "### Constraints\n",
    "\n",
    "1. **Cluster Capacity:**\n",
    "\n",
    "   - The sum of vCPUs, RAM, and disk space used by VMs on cluster $j$ should not exceed the cluster's capacity.\n",
    "\n",
    "    $$\\sum_{i=1}^{n} x_{ij} \\cdot \\text{vcpu}_i \\leq \\text{vcpu}_j y_i, \\forall j \\in \\{1, \\ldots, m\\}$$\n",
    "\n",
    "    $$\\sum_{i=1}^{n} x_{ij} \\cdot \\text{ram}_i \\leq \\text{ram}_j y_i, \\forall j \\in \\{1, \\ldots, m\\}$$\n",
    "\n",
    "    $$\\sum_{i=1}^{n} x_{ij} \\cdot \\text{disk}_i \\leq \\text{disk}_j y_i, \\forall j \\in \\{1, \\ldots, m\\}$$\n",
    "\n",
    "\n",
    "2. **VM Placement:**\n",
    "\n",
    "    - Each VM should be placed on exactly one cluster.\n",
    "    \n",
    "      $$\\sum_{j=1}^{m} x_{ij} = 1, \\forall i \\in \\{1, \\ldots, n\\}$$\n",
    "\n",
    "3. **Decision Variables bounds:**\n",
    "\n",
    "    - $x_{ij} \\in \\{0, 1\\}, \\forall i \\in \\{1, \\ldots, n\\}, j \\in \\{1, \\ldots, m\\}$\n",
    "    - $y_i \\in \\{0, 1\\}, \\forall i \\in \\{1, \\ldots, n\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation in Python\n",
    "\n",
    "We will use the `milp` and `LinearConstraint` classes from the `scipy.optimize` module to implement the optimization model.\n",
    "\n",
    "The idea is to formulate the problem as a Mixed-Integer Linear Programming (MILP) model and solve it using the `linprog` function.\n",
    "\n",
    "$$\\text{Minimize} \\quad c \\cdot x$$\n",
    "$$\\text{Subject to:} \\quad lb \\leq A \\cdot x \\leq ub$$\n",
    "\n",
    "where:\n",
    "- $x$ is the vector of decision variables : x= $[y_1, \\ldots, y_n, x_{1,1}, x_{1,2}, \\ldots, x_{1,m}, x_{2,1}, \\ldots, x_{n,m}]$\n",
    "- $c$ is the coefficient vector of the objective function. c=$[1, \\ldots, 1, 0, \\ldots, 0]$\n",
    "\n",
    "- $A$ is the matrix of constraints.\n",
    "- $lb$ and $ub$ are the lower and upper bounds of the constraints.\n",
    "\n",
    "For instance we will rewrite the constraints to fit the linear programming format:\n",
    "\n",
    "$$ -\\infty \\leq  -\\text{vcpu}_j y_i + \\sum_{i=1}^{n} x_{ij} \\cdot \\text{vcpu}_i \\leq 0, \\quad \\forall j \\in \\{1, \\ldots, m\\}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters used: 4\n"
     ]
    }
   ],
   "source": [
    "def one_constraint_A(clusters, vms, constraint_idx):\n",
    "    \"\"\"\n",
    "    A helper function to generate the constraint matrix for a single constraint (e.g. CPU, Memory, Disk Space)\n",
    "    \n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "    constraint_idx: int - the index of the constraint to generate the matrix for\n",
    "\n",
    "    Output:\n",
    "    A: np.array(float) - the constraint matrix for the given constraint_idx\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_constraints = clusters[:, constraint_idx].astype(float)\n",
    "    vm_constraints = vms[:, constraint_idx].astype(float)\n",
    "    n_clusters = len(cluster_constraints)\n",
    "    n_vms = len(vm_constraints)\n",
    "    A = np.zeros((n_clusters, n_clusters + n_clusters*n_vms))\n",
    "    for i in range(n_clusters):\n",
    "        A[i, i] = -cluster_constraints[i]\n",
    "        A[i, n_clusters:][[\n",
    "            i + j * n_clusters for j in range(n_clusters)]] = vm_constraints\n",
    "    return A\n",
    "\n",
    "\n",
    "def bin_packing(clusters, vms):\n",
    "    \"\"\" \n",
    "    Bin packing problem:\n",
    "    Given a set of clusters and a set of VMs, assign each VM to a cluster such that\n",
    "    the total resource usage of each cluster does not exceed the capacity of the cluster.\n",
    "    \n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "\n",
    "    Output:\n",
    "    cluster_assignment: np.array(int) - a list of cluster assignments for each VM\n",
    "    vms_assignment: np.array(int) - a list of VM assignments to each cluster\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    # Define sizes\n",
    "    n_cluster = len(clusters)\n",
    "    n_vm = len(vms)\n",
    "    n_constraints = vms.shape[1] - 1 # remove the name column\n",
    "    n_var = n_cluster + n_cluster*n_vm\n",
    "\n",
    "    # Define the objective function\n",
    "    c = np.zeros(n_var)\n",
    "    c[:n_cluster] = 1\n",
    "\n",
    "    # Define the constraints\n",
    "    # constraints on the variables\n",
    "    A = np.zeros((n_var + n_vm, n_var))\n",
    "    A[:n_var] = np.eye(n_var)\n",
    "\n",
    "    # constraints on the coefficients of the VMs\n",
    "    for i in range(n_vm):\n",
    "        A[n_var + i, n_cluster + i*n_cluster:n_cluster + (i+1)*n_cluster] = np.ones(n_cluster)\n",
    "\n",
    "    # constraints on the cluster capacities\n",
    "    for i in range(n_constraints):\n",
    "        A = np.concatenate((A, one_constraint_A(clusters, vms, i+1)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster, n_var)\n",
    "\n",
    "    # Define the upper and lower bounds\n",
    "    ub = np.concatenate((np.ones(n_var + n_vm), np.zeros(n_cluster*n_constraints)))\n",
    "    lb = np.concatenate((np.zeros(n_var), np.ones(n_vm), [-np.inf]*(n_cluster*n_constraints)))\n",
    "\n",
    "    # Define the integrality\n",
    "    integrality = np.array([True]*n_var)\n",
    "\n",
    "    # Define the constraints as a LinearConstraint object\n",
    "    constraints = LinearConstraint(A, lb, ub)\n",
    "\n",
    "    # Solve the problem\n",
    "    res = milp(c=c, constraints=constraints, integrality=integrality)\n",
    "\n",
    "    # Number of clusters used\n",
    "    n_clusters_used = int(sum(res.x[:n_cluster]))\n",
    "    print(f\"Number of clusters used: {n_clusters_used}\")\n",
    "    \n",
    "    # Return the results (cluster assignment, vm assignment)\n",
    "    return res.x[:n_cluster], res.x[n_cluster:].reshape(n_vm, n_cluster)\n",
    "\n",
    "# # change numpy print options\n",
    "# np.set_printoptions(linewidth=1000)\n",
    "\n",
    "assign_cluster, assign_vm = bin_packing(clusters, vms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Name             \tCPU usage (%)\tMem usage (%)\tDisk usage (%)\tAssigned VMs\n",
      "us-west1-Epsilon-698     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Iota-294        \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Eta-76          \t15.38%\t\t28.12%\t\t29.73%\t\tSoggyMuffin-509\n",
      "us-west2-Delta-987       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west1-Epsilon-543     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Theta-546       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Alpha-908       \t18.60%\t\t97.06%\t\t91.89%\t\tBouncyOctopus-345, JollyMuffin-500\n",
      "us-west3-Gamma-927       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-east2-Beta-405        \t24.56%\t\t90.74%\t\t96.67%\t\tZestyPancake-680, SoggyBanana-733, GrumpyBanana-870\n",
      "us-east2-Theta-519       \t53.85%\t\t82.76%\t\t100.00%\t\tWobblyPenguin-505, QuirkyPancake-663, SpicyToaster-948, SpicyNoodle-992\n"
     ]
    }
   ],
   "source": [
    "def pretty_assignment_print(clusters, assign_vm, vms):\n",
    "    \"\"\"\n",
    "    Pretty print the assignment of VMs to clusters\"\n",
    "    \"\"\"\n",
    "  \n",
    "    max_len_name = max([len(cluster[0]) for cluster in clusters]) + 5\n",
    "    print(f\"Cluster Name{' '*(max_len_name-12)}\\tCPU usage (%)\\tMem usage (%)\\tDisk usage (%)\\tAssigned VMs\")\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        criticity = len(vms[0]) == 5\n",
    "        assigned_vms = [vms[j][0] for j in range(len(vms)) if assign_vm[j][i] == 1]\n",
    "        vCPU = sum([int(vms[j][1]) for j in range(len(vms)) if assign_vm[j][i] == 1])\n",
    "        mem = sum([int(vms[j][2]) for j in range(len(vms)) if assign_vm[j][i] == 1])\n",
    "        disk = sum([int(vms[j][3]) for j in range(len(vms)) if assign_vm[j][i] == 1])\n",
    "\n",
    "        cluter_cpu = int(cluster[1])\n",
    "        cluster_mem = int(cluster[2])\n",
    "        cluster_disk = int(cluster[3])\n",
    "        cpu_usage = vCPU / cluter_cpu \n",
    "        mem_usage = mem / cluster_mem \n",
    "        disk_usage = disk / cluster_disk \n",
    "        assigned_vm_names = \", \".join(assigned_vms)\n",
    "        if criticity:\n",
    "            assigned_vm_with_criticity = []\n",
    "            for j in range(len(vms)):\n",
    "                if assign_vm[j][i] == 1:\n",
    "                    assigned_vm_with_criticity.append(f\"{vms[j][0]} ({vms[j][4]})\")\n",
    "            assigned_vm_names = \", \".join(assigned_vm_with_criticity)\n",
    "\n",
    "        print(f\"{cluster[0]+ ' '*(max_len_name - len(cluster[0]))}\\t{cpu_usage*100:.2f}%\\t\\t{mem_usage*100:.2f}%\\t\\t{disk_usage*100:.2f}%\\t\\t{assigned_vm_names}\")\n",
    "\n",
    "\n",
    "pretty_assignment_print(clusters, assign_vm, vms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Affinity rules between some set of VMs\n",
    "\n",
    "some VMs could share a cluster / some others couln't (affinity / anti-affinity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "        \\min \\quad & \\sum_{i=1}^{u} y_i \\\\\n",
    "        \\text{s.t.} \\quad & \\sum_{j=1}^{n} w_j x_{ij} \\leq c y_i, \\quad \\forall i = 1, \\dots, u \\\\\n",
    "        & \\sum_{i=1}^{u} x_{ij} = 1, \\quad \\forall j = 1, \\dots, n \\\\\n",
    "        & x_{ij} \\in \\{0,1\\}, \\quad y_i \\in \\{0,1\\}, \\quad \\forall i,j\n",
    "    \\end{align*}$$\n",
    "\n",
    " where:\n",
    "- $y_i = 1$ if bin $i$ is used, 0 otherwise.\n",
    "- $x_{ij} = 1$ if item $j$ is placed in bin $i$, 0 otherwise.\n",
    "\n",
    "to add an affinity rule, we can add a constraints that force the VMs to be in the same cluster or in different clusters :\n",
    "\n",
    "$$\\begin{align*}\n",
    "        x_{ij} = x_{i'j}, \\quad \\forall i,i' \\in \\text{affinity\\_rule} \\quad \\forall j \\in \\{1, \\ldots, n\\}\n",
    "    \\end{align*}$$\n",
    "\n",
    "to add non-affinity rule, we can add a constraints that force the VMs to be in different clusters :\n",
    "$$\\begin{align*}\n",
    "        x_{ij} + x_{i'j} \\leq 1, \\quad \\forall i,i' \\in \\text{non\\_affinity\\_rule} \\quad \\forall j \\in \\{1, \\ldots, n\\}\n",
    "    \\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters used: 4\n"
     ]
    }
   ],
   "source": [
    "def affinity_constraint(clusters, vms, vm_index_1, vm_index_2):\n",
    "    \"\"\"\n",
    "    A helper function to generate the constraint matrix for a single affinity constraint\"\n",
    "    \n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "    vm_index_1: int - the index of the first VM\n",
    "    vm_index_2: int - the index of the second VM\n",
    "\n",
    "    Output:\n",
    "    A: np.array(float) - the constraint matrix for the given affinity constraint\n",
    "    \"\"\"\n",
    "\n",
    "    n_clusters = len(clusters)\n",
    "    n_vms = len(vms)\n",
    "    A = np.zeros((n_clusters, n_clusters + n_clusters*n_vms))\n",
    "    for i in range(n_clusters):\n",
    "        A[i, n_clusters:][[i + vm_index_1 *n_clusters, i + vm_index_2 *n_clusters]] = np.array([1, -1]) # x_ij - x_ik = 0\n",
    "    return A\n",
    "\n",
    "def non_affinity_constraint(clusters, vms, vm_index_1, vm_index_2):\n",
    "    \"\"\"A helper function to generate the constraint matrix for a single non-affinity constraint\n",
    "\n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "    vm_index_1: int - the index of the first VM\n",
    "    vm_index_2: int - the index of the second VM\n",
    "\n",
    "    Output:\n",
    "    A: np.array(float) - the constraint matrix for the given non-affinity constraint\n",
    "    \"\"\"\n",
    "\n",
    "    n_clusters = len(clusters)\n",
    "    n_vms = len(vms)\n",
    "    A = np.zeros((n_clusters, n_clusters + n_clusters*n_vms))\n",
    "    for i in range(n_clusters):\n",
    "        A[i, n_clusters:][[i + vm_index_1 *n_clusters, i + vm_index_2 *n_clusters]] = np.array([1, 1]) # x_ij + x_ik <= 1\n",
    "    return A\n",
    "\n",
    "\n",
    "def bin_packing_affinity(clusters, vms, affinity_constraints=[], non_affinity_constraints=[]):\n",
    "    \"\"\" \n",
    "    Bin packing problem:\n",
    "    Given a set of clusters and a set of VMs, assign each VM to a cluster such that\n",
    "    the total resource usage of each cluster does not exceed the capacity of the cluster.\n",
    "    \n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "\n",
    "    Output:\n",
    "    cluster_assignment: np.array(int) - a list of cluster assignments for each VM\n",
    "    vms_assignment: np.array(int) - a list of VM assignments to each cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # Define sizes\n",
    "    n_cluster = len(clusters)\n",
    "    n_vm = len(vms)\n",
    "    n_constraints = vms.shape[1] - 1  # remove the name column\n",
    "    n_var = n_cluster + n_cluster*n_vm\n",
    "    n_affinity_constraints = len(affinity_constraints)\n",
    "    n_non_affinity_constraints = len(non_affinity_constraints)\n",
    "\n",
    "    # Define the objective function\n",
    "    c = np.zeros(n_var)\n",
    "    c[:n_cluster] = 1\n",
    "\n",
    "    # Define the constraints\n",
    "    # constraints on the variables\n",
    "    A = np.zeros((n_var + n_vm, n_var))\n",
    "    A[:n_var] = np.eye(n_var)\n",
    "\n",
    "    # constraints on the coefficients of the VMs\n",
    "    for i in range(n_vm):\n",
    "        A[n_var + i, n_cluster + i*n_cluster:n_cluster +\n",
    "            (i+1)*n_cluster] = np.ones(n_cluster)\n",
    "\n",
    "    # constraints on the cluster capacities\n",
    "    for i in range(n_constraints):\n",
    "        A = np.concatenate((A, one_constraint_A(clusters, vms, i+1)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster, n_var)\n",
    "\n",
    "    # constraints on the affinity constraints\n",
    "    for vm_index_1, vm_index_2 in affinity_constraints:\n",
    "        A = np.concatenate((A, affinity_constraint(clusters, vms, vm_index_1, vm_index_2)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster + n_affinity_constraints*n_cluster, n_var)\n",
    "\n",
    "    # constraints on the non-affinity constraints\n",
    "    for vm_index_1, vm_index_2 in non_affinity_constraints:\n",
    "        A = np.concatenate((A, non_affinity_constraint(clusters, vms, vm_index_1, vm_index_2)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster + n_affinity_constraints*n_cluster + n_non_affinity_constraints*n_cluster, n_var)\n",
    "\n",
    "    # Define the upper and lower bounds\n",
    "    ub = np.concatenate(\n",
    "        (np.ones(n_var + n_vm), np.zeros(n_cluster*n_constraints), np.zeros(n_cluster*n_affinity_constraints), np.ones(n_cluster*n_non_affinity_constraints)))\n",
    "    lb = np.concatenate((np.zeros(n_var), np.ones(\n",
    "        n_vm), [-np.inf]*(n_cluster*n_constraints), np.zeros(n_cluster*n_affinity_constraints), [-np.inf]*(n_cluster*n_non_affinity_constraints)))\n",
    "\n",
    "    # Define the integrality\n",
    "    integrality = np.array([True]*n_var)\n",
    "\n",
    "    # Define the constraints as a LinearConstraint object\n",
    "    constraints = LinearConstraint(A, lb, ub)\n",
    "\n",
    "    # Solve the problem\n",
    "    res = milp(c=c, constraints=constraints, integrality=integrality)\n",
    "\n",
    "    # Number of clusters used\n",
    "    n_clusters_used = int(sum(res.x[:n_cluster]))\n",
    "    print(f\"Number of clusters used: {n_clusters_used}\")\n",
    "\n",
    "    # Return the results (cluster assignment, vm assignment)\n",
    "    return res.x[:n_cluster], res.x[n_cluster:].reshape(n_vm, n_cluster), res\n",
    "\n",
    "# # change numpy print options\n",
    "# np.set_printoptions(linewidth=1000)\n",
    "\n",
    "affinity_constraints = [(0, 1), (0, 2), (6, 7)]\n",
    "non_affinity_constraints = [(0, 3), (0, 4), (0,5)]\n",
    "\n",
    "assign_cluster, assign_vm, res = bin_packing_affinity(clusters, vms, affinity_constraints, non_affinity_constraints) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM ID\tVM Name               \tvCPU\tMemory(GB)\tDisk Space(GB)\n",
      "0\tWobblyPenguin-505     \t4\t22\t\t24\t\t\n",
      "1\tQuirkyPancake-663     \t3\t11\t\t4\t\t\n",
      "2\tSoggyMuffin-509       \t8\t9\t\t11\t\t\n",
      "3\tZestyPancake-680      \t7\t10\t\t6\t\t\n",
      "4\tBouncyOctopus-345     \t5\t22\t\t16\t\t\n",
      "5\tSpicyToaster-948      \t3\t10\t\t12\t\t\n",
      "6\tSoggyBanana-733       \t3\t21\t\t26\t\t\n",
      "7\tSpicyNoodle-992       \t4\t5\t\t22\t\t\n",
      "8\tJollyMuffin-500       \t3\t11\t\t18\t\t\n",
      "9\tGrumpyBanana-870      \t4\t18\t\t26\t\t\n"
     ]
    }
   ],
   "source": [
    "show_vms(vms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Name             \tCPU usage (%)\tMem usage (%)\tDisk usage (%)\tAssigned VMs\n",
      "us-west1-Epsilon-698     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Iota-294        \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Eta-76          \t21.15%\t\t87.50%\t\t86.49%\t\tZestyPancake-680, GrumpyBanana-870\n",
      "us-west2-Delta-987       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west1-Epsilon-543     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Theta-546       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Alpha-908       \t18.60%\t\t97.06%\t\t91.89%\t\tBouncyOctopus-345, JollyMuffin-500\n",
      "us-west3-Gamma-927       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-east2-Beta-405        \t17.54%\t\t66.67%\t\t100.00%\t\tSpicyToaster-948, SoggyBanana-733, SpicyNoodle-992\n",
      "us-east2-Theta-519       \t57.69%\t\t72.41%\t\t62.90%\t\tWobblyPenguin-505, QuirkyPancake-663, SoggyMuffin-509\n"
     ]
    }
   ],
   "source": [
    "pretty_assignment_print(clusters, assign_vm, vms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can see that:\n",
      "VM 0 WobblyPenguin-505 and VM 1 QuirkyPancake-663 are assigned to the same cluster\n",
      "VM 0 WobblyPenguin-505 and VM 2 SoggyMuffin-509 are assigned to the same cluster\n",
      "VM 6 SoggyBanana-733 and VM 7 SpicyNoodle-992 are assigned to the same cluster\n",
      "VM 0 WobblyPenguin-505 and VM 3 ZestyPancake-680 are assigned to different clusters\n",
      "VM 0 WobblyPenguin-505 and VM 4 BouncyOctopus-345 are assigned to different clusters\n",
      "VM 0 WobblyPenguin-505 and VM 5 SpicyToaster-948 are assigned to different clusters\n"
     ]
    }
   ],
   "source": [
    "print(\"We can see that:\")\n",
    "for vm1, vm2 in affinity_constraints:\n",
    "    print(f\"VM {vm1} {vms[vm1][0]} and VM {vm2} {vms[vm2][0]} are assigned to the same cluster\")\n",
    "\n",
    "for vm1, vm2 in non_affinity_constraints:\n",
    "    print(f\"VM {vm1} {vms[vm1][0]} and VM {vm2} {vms[vm2][0]} are assigned to different clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. All servers are partly occupied vs totally empty and all with the same characteristics\n",
    "\n",
    "We already have the constraint that all servers are partly occupied in the basic model as the cluster capacities are randomly generated. To have all server empty we can now generate cluster with same capacities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster ID\tCluster Name             \tvCPU\tMemory(GB)\tDisk Space(GB)\n",
      "0\t\tus-west3-Eta-809         \t64\t64\t\t128\n",
      "1\t\tus-east3-Alpha-751       \t64\t64\t\t128\n",
      "2\t\tus-east3-Epsilon-183     \t64\t64\t\t128\n",
      "3\t\tus-west2-Delta-486       \t64\t64\t\t128\n",
      "4\t\tus-east1-Kappa-940       \t64\t64\t\t128\n",
      "5\t\tus-west3-Kappa-596       \t64\t64\t\t128\n",
      "6\t\tus-east3-Delta-741       \t64\t64\t\t128\n",
      "7\t\tus-west3-Theta-48        \t64\t64\t\t128\n",
      "8\t\tus-west2-Alpha-372       \t64\t64\t\t128\n",
      "9\t\tus-west3-Kappa-901       \t64\t64\t\t128\n"
     ]
    }
   ],
   "source": [
    "same_clusters = generate_cluster(10, random_=False)\n",
    "show_clusters(same_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters used: 2\n",
      "Cluster Name             \tCPU usage (%)\tMem usage (%)\tDisk usage (%)\tAssigned VMs\n",
      "us-west3-Eta-809         \t10.94%\t\t15.62%\t\t4.69%\t\tZestyPancake-680\n",
      "us-east3-Alpha-751       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-east3-Epsilon-183     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Delta-486       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-east1-Kappa-940       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Kappa-596       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-east3-Delta-741       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Theta-48        \t35.94%\t\t89.06%\t\t50.78%\t\tQuirkyPancake-663, SoggyMuffin-509, BouncyOctopus-345, SpicyToaster-948, SpicyNoodle-992\n",
      "us-west2-Alpha-372       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Kappa-901       \t6.25%\t\t34.38%\t\t18.75%\t\tWobblyPenguin-505\n"
     ]
    }
   ],
   "source": [
    "# bin packing basic model\n",
    "assign_cluster, assign_vm = bin_packing(same_clusters, vms)\n",
    "pretty_assignment_print(same_clusters, assign_vm, vms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. VMs could be splitted over several servers\n",
    "\n",
    "VMs could be splitted over several servers using some float variables $x_{ij}$ between 0 and 1. In fact, this variable was already used in the basic model but it was considered as a binary variable. We can now consider it as a float variable. With MILP, this changement is easy to do, we just need to change the type of the variable in the `integrality` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters used: 4\n",
      "Cluster Name             \tCPU usage (%)\tMem usage (%)\tDisk usage (%)\tAssigned VMs\n",
      "us-west1-Epsilon-698     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Iota-294        \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Eta-76          \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Delta-987       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west1-Epsilon-543     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Theta-546       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Alpha-908       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Gamma-927       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-east2-Beta-405        \t31.58%\t\t55.56%\t\t58.33%\t\tSoggyMuffin-509, ZestyPancake-680, JollyMuffin-500\n",
      "us-east2-Theta-519       \t38.46%\t\t67.24%\t\t67.74%\t\tQuirkyPancake-663, SpicyToaster-948, GrumpyBanana-870\n"
     ]
    }
   ],
   "source": [
    "def splitted_bin_packing(clusters, vms):\n",
    "    \"\"\"\n",
    "    splitted big packing problem:\n",
    "    Given a set of clusters and a set of VMs, assign a COEFFICIENT for each VM to a cluster such that\n",
    "    the total resource usage of each cluster does not exceed the capacity of the cluster.\n",
    "    The objective is to minimize the number of clusters used.\n",
    "\n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "\n",
    "    Output:\n",
    "    cluster_assignment: np.array(int) - a list of cluster assignments for each VM\n",
    "    vm_assignment: np.array(float) - a list of coefficients for each VM to each cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # Define sizes\n",
    "    n_cluster = len(clusters)\n",
    "    n_vm = len(vms)\n",
    "    n_constraints = vms.shape[1] - 1 # remove the name column\n",
    "    n_var = n_cluster + n_cluster*n_vm\n",
    "\n",
    "    # Define the objective function\n",
    "    c = np.zeros(n_var)\n",
    "    c[:n_cluster] = 1\n",
    "\n",
    "    # Define the constraints\n",
    "    # constraints on the variables\n",
    "    A = np.zeros((n_var + n_vm, n_var))\n",
    "    A[:n_var] = np.eye(n_var)\n",
    "\n",
    "    # constraints on the coefficients of the VMs\n",
    "    for i in range(n_vm):\n",
    "        A[n_var + i, n_cluster + i*n_cluster:n_cluster + (i+1)*n_cluster] = np.ones(n_cluster)\n",
    "\n",
    "    # constraints on the cluster capacities\n",
    "    for i in range(n_constraints):\n",
    "        A = np.concatenate((A, one_constraint_A(clusters, vms, i+1)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster, n_var)\n",
    "\n",
    "    # Define the upper and lower bounds\n",
    "    ub = np.concatenate((np.ones(n_var + n_vm), np.zeros(n_cluster*n_constraints)))\n",
    "    lb = np.concatenate((np.zeros(n_var), np.ones(n_vm), [-np.inf]*(n_cluster*n_constraints)))\n",
    "\n",
    "    # Define the integrality\n",
    "    integrality = np.array([True]*n_cluster + [False]*n_cluster*n_vm)\n",
    "\n",
    "    # Define the constraints as a LinearConstraint object\n",
    "    constraints = LinearConstraint(A, lb, ub)\n",
    "\n",
    "    # Solve the problem\n",
    "    res = milp(c=c, constraints=constraints, integrality=integrality)\n",
    "\n",
    "    # Number of clusters used\n",
    "    n_clusters_used = int(sum(res.x[:n_cluster]))\n",
    "    print(f\"Number of clusters used: {n_clusters_used}\")\n",
    "\n",
    "    # Return the results (cluster assignment, vm assignment)\n",
    "    return res.x[:n_cluster], res.x[n_cluster:].reshape(n_vm, n_cluster)\n",
    "\n",
    "\n",
    "assign_cluster, assign_vm = splitted_bin_packing(clusters, vms)\n",
    "pretty_assignment_print(clusters, assign_vm, vms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sure that know VM is splitted over several servers by looking at the coefficient of the variable $x_{ij}$ in the resulting solution. If the coefficient is 1, the VM is not splitted, if it is between 0 and 1, the VM is splitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.   -0.    0.    0.    0.63  0.    0.    0.37]\n",
      " [ 0.    0.   -0.   -0.   -0.    0.    0.    0.    0.    1.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]\n",
      " [ 0.    0.    0.   -0.    0.    0.    0.    0.    1.    0.  ]\n",
      " [ 0.    0.   -0.    0.    0.    0.    0.37  0.    0.42  0.21]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]\n",
      " [-0.   -0.    0.    0.   -0.    0.    0.    0.    0.7   0.3 ]\n",
      " [ 0.    0.    0.    0.    0.    0.82  0.18 -0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    1.   -0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.   -0.    0.    0.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(assign_vm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Consider VMs families, each family is given a criticity level between 1 to 3\n",
    "\n",
    "Now each VM has a criticity level between 1 and 3. We can add a constraint that force the VMs of criticity level 1 and 3 to be in different clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM ID\tVM Name                 \tvCPU\tMemory(GB)\tDisk Space(GB)\tCriticity\n",
      "0\tWobblyPickle-810        \t2\t7\t\t19\t\t1\n",
      "1\tGrumpyBanana-105        \t6\t10\t\t13\t\t3\n",
      "2\tQuirkyBanana-707        \t7\t13\t\t6\t\t3\n",
      "3\tWobblySasquatch-278     \t4\t9\t\t18\t\t1\n",
      "4\tJollyToaster-251        \t4\t19\t\t2\t\t3\n",
      "5\tGrumpyToaster-799       \t2\t16\t\t30\t\t3\n",
      "6\tSpicyOctopus-341        \t5\t2\t\t15\t\t3\n",
      "7\tBouncyNoodle-758        \t6\t17\t\t18\t\t3\n",
      "8\tQuirkyNoodle-444        \t7\t10\t\t6\t\t1\n",
      "9\tGrumpyBanana-645        \t5\t4\t\t32\t\t2\n"
     ]
    }
   ],
   "source": [
    "vms_critical = generate_vm(10, criticity=True)\n",
    "show_vms(vms_critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters used: 4\n"
     ]
    }
   ],
   "source": [
    "def create_non_affinity_constraints_from_critical_vms(vms):\n",
    "    \"\"\"\n",
    "    Create non-affinity constraints from critical vms\n",
    "    \"\"\"\n",
    "    n_vms = len(vms)\n",
    "    non_affinity_constraints = []\n",
    "    for i in range(n_vms):\n",
    "        for j in range(i+1, n_vms):\n",
    "            if (int(vms[i][4]) == 3 and int(vms[j][4]) == 1) or (int(vms[i][4]) == 1 and int(vms[j][4]) == 3):\n",
    "                non_affinity_constraints.append((i, j))\n",
    "    return non_affinity_constraints\n",
    "\n",
    "\n",
    "def bin_packing_criticity(clusters, vms):\n",
    "    \"\"\" \n",
    "    Bin packing problem:\n",
    "    Given a set of clusters and a set of VMs, assign each VM to a cluster such that\n",
    "    the total resource usage of each cluster does not exceed the capacity of the cluster.\n",
    "    \n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "\n",
    "    Output:\n",
    "    cluster_assignment: np.array(int) - a list of cluster assignments for each VM\n",
    "    vms_assignment: np.array(int) - a list of VM assignments to each cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # Define sizes\n",
    "    n_cluster = len(clusters)\n",
    "    n_vm = len(vms)\n",
    "    n_constraints = vms.shape[1] - 2  # remove the name column and the criticity column\n",
    "    n_var = n_cluster + n_cluster*n_vm\n",
    "\n",
    "    # Define the objective function\n",
    "    c = np.zeros(n_var)\n",
    "    c[:n_cluster] = 1\n",
    "\n",
    "    # Define the constraints\n",
    "    # constraints on the variables\n",
    "    A = np.zeros((n_var + n_vm, n_var))\n",
    "    A[:n_var] = np.eye(n_var)\n",
    "\n",
    "    # constraints on the coefficients of the VMs\n",
    "    for i in range(n_vm):\n",
    "        A[n_var + i, n_cluster + i*n_cluster:n_cluster +\n",
    "            (i+1)*n_cluster] = np.ones(n_cluster)\n",
    "\n",
    "    # constraints on the cluster capacities\n",
    "    for i in range(n_constraints):\n",
    "        A = np.concatenate((A, one_constraint_A(clusters, vms, i+1)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster, n_var)\n",
    "\n",
    "\n",
    "    # define non-affinity constraints from critical vms\n",
    "    non_affinity_constraints = create_non_affinity_constraints_from_critical_vms(vms)\n",
    "\n",
    "    n_non_affinity_constraints = len(non_affinity_constraints)\n",
    "\n",
    "    # constraints on the non-affinity constraints\n",
    "    for vm_index_1, vm_index_2 in non_affinity_constraints:\n",
    "        A = np.concatenate((A, non_affinity_constraint(\n",
    "            clusters, vms, vm_index_1, vm_index_2)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster + n_affinity_constraints*n_cluster + n_non_affinity_constraints*n_cluster, n_var)\n",
    "\n",
    "    # Define the upper and lower bounds\n",
    "    ub = np.concatenate(\n",
    "        (np.ones(n_var + n_vm), np.zeros(n_cluster*n_constraints), np.ones(n_cluster*n_non_affinity_constraints)))\n",
    "    lb = np.concatenate((np.zeros(n_var), np.ones(\n",
    "        n_vm), [-np.inf]*(n_cluster*n_constraints), [-np.inf]*(n_cluster*n_non_affinity_constraints)))\n",
    "\n",
    "    # Define the integrality\n",
    "    integrality = np.array([True]*n_var)\n",
    "\n",
    "    # Define the constraints as a LinearConstraint object\n",
    "    constraints = LinearConstraint(A, lb, ub)\n",
    "\n",
    "    # Solve the problem\n",
    "    res = milp(c=c, constraints=constraints, integrality=integrality)\n",
    "\n",
    "    # Number of clusters used\n",
    "    n_clusters_used = sum([1 for i in res.x[:n_cluster] if i > 0.5])\n",
    "    print(f\"Number of clusters used: {n_clusters_used}\")\n",
    "\n",
    "    # Return the results (cluster assignment, vm assignment)\n",
    "    return res.x[:n_cluster], res.x[n_cluster:].reshape(n_vm, n_cluster), res\n",
    "\n",
    "# # change numpy print options\n",
    "# np.set_printoptions(linewidth=1000)\n",
    "\n",
    "assign_cluster, assign_vm, res = bin_packing_criticity(clusters, vms_critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Name             \tCPU usage (%)\tMem usage (%)\tDisk usage (%)\tAssigned VMs\n",
      "us-west1-Epsilon-698     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Iota-294        \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west3-Eta-76          \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Delta-987       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west1-Epsilon-543     \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-west2-Theta-546       \t35.00%\t\t91.67%\t\t68.92%\t\tWobblyPickle-810 (1), GrumpyBanana-645 (2)\n",
      "us-west3-Alpha-908       \t27.91%\t\t79.41%\t\t83.78%\t\tGrumpyBanana-105 (3), BouncyNoodle-758 (3)\n",
      "us-west3-Gamma-927       \t0.00%\t\t0.00%\t\t0.00%\t\t\n",
      "us-east2-Beta-405        \t19.30%\t\t35.19%\t\t40.00%\t\tWobblySasquatch-278 (1), QuirkyNoodle-444 (1)\n",
      "us-east2-Theta-519       \t69.23%\t\t86.21%\t\t85.48%\t\tQuirkyBanana-707 (3), JollyToaster-251 (3), GrumpyToaster-799 (3), SpicyOctopus-341 (3)\n"
     ]
    }
   ],
   "source": [
    "# pretty print the results\n",
    "pretty_assignment_print(clusters, assign_vm, vms_critical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the rule to separate the VMs of criticity level 1 and 3 is respected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
