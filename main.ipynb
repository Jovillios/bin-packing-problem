{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bin Packing Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.optimize import milp, LinearConstraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate data\n",
    "\n",
    "Create VMs with random vcpu, memory and disk requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM Name                 vCPU\tMemory(GB)\tDisk Space(GB)\n",
      "FluffyToaster-708       \t1\t24\t\t21\n",
      "BouncyMuffin-691        \t7\t15\t\t21\n",
      "FluffyPancake-174       \t5\t9\t\t32\n",
      "SpicyToaster-434        \t6\t4\t\t32\n",
      "BouncyPenguin-903       \t5\t22\t\t14\n",
      "ZestyPickle-890         \t3\t11\t\t11\n",
      "QuirkyPickle-551        \t2\t2\t\t9\n",
      "SpicyBanana-557         \t3\t6\t\t5\n",
      "WobblySasquatch-961     \t7\t16\t\t4\n",
      "FluffyMuffin-527        \t7\t15\t\t25\n"
     ]
    }
   ],
   "source": [
    "def generate_vm_name():\n",
    "    adjectives = [\"Wobbly\", \"Fluffy\", \"Spicy\", \"Grumpy\",\n",
    "                  \"Sneaky\", \"Jolly\", \"Zesty\", \"Quirky\", \"Bouncy\", \"Soggy\"]\n",
    "    nouns = [\"Penguin\", \"Toaster\", \"Banana\", \"Octopus\", \"Pancake\",\n",
    "             \"Noodle\", \"Cactus\", \"Sasquatch\", \"Pickle\", \"Muffin\"]\n",
    "    number = random.randint(1, 999)\n",
    "    return f\"{random.choice(adjectives)}{random.choice(nouns)}-{number}\"\n",
    "\n",
    "\n",
    "def generate_vm(n: int, max_vcpu=8, max_memory=24, max_disk_space=32) -> list :\n",
    "    \"\"\"\"\n",
    "    Generate a list of VMs using random features\n",
    "\n",
    "    Input:\n",
    "    n: int - number of VMs to generate\n",
    "    \"\"\"\n",
    "    res = []\n",
    "\n",
    "    for i in range(n):\n",
    "        # generate VM name\n",
    "        vm_name = generate_vm_name()\n",
    "        # generate vCPU\n",
    "        vcpu = random.randint(1, max_vcpu)\n",
    "        # generate Memory (GB)\n",
    "        memory = random.randint(1, max_memory)\n",
    "        # generate Disk Space (GB)\n",
    "        disk_space = random.randint(1, max_disk_space)\n",
    "        res.append([vm_name, vcpu, memory, disk_space])\n",
    "    # type cast to numpy array for better performance\n",
    "    return np.array(res)\n",
    "\n",
    "def show_vms(vms: list):\n",
    "    max_len_name = max([len(vm[0]) for vm in vms]) + 5\n",
    "    print(f\"VM Name{' '*(max_len_name-7)}vCPU\\tMemory(GB)\\tDisk Space(GB)\")\n",
    "    for vm in vms:\n",
    "        print(f\"{vm[0]+ ' '*(max_len_name - len(vm[0]))}\\t{vm[1]}\\t{vm[2]}\\t\\t{vm[3]}\")\n",
    "\n",
    "vms = generate_vm(10)\n",
    "show_vms(vms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U21')"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vms[:,1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Name           \tvCPU\tMemory(GB)\tDisk Space(GB)\n",
      "us-west1-Zeta-864      \t1\t8\t\t53\n",
      "us-east3-Alpha-238     \t9\t27\t\t11\n",
      "us-east1-Iota-619      \t54\t21\t\t82\n",
      "us-west1-Gamma-943     \t58\t4\t\t90\n",
      "us-west1-Zeta-431      \t47\t43\t\t67\n",
      "us-west2-Gamma-887     \t56\t33\t\t13\n",
      "us-east1-Beta-91       \t11\t7\t\t50\n",
      "us-west2-Eta-739       \t29\t14\t\t93\n",
      "us-west2-Eta-771       \t10\t40\t\t74\n",
      "us-east2-Eta-567       \t53\t17\t\t73\n"
     ]
    }
   ],
   "source": [
    "def generate_cluster_name():\n",
    "    zones = [\"us-west1\", \"us-west2\", \"us-west3\", \"us-east1\", \"us-east2\", \"us-east3\"]\n",
    "    names = [\"Alpha\", \"Beta\", \"Gamma\", \"Delta\", \"Epsilon\", \"Zeta\", \"Eta\", \"Theta\", \"Iota\", \"Kappa\"]\n",
    "    number = random.randint(1, 999)\n",
    "    return f\"{random.choice(zones)}-{random.choice(names)}-{number}\"\n",
    "\n",
    "def generate_cluster(n: int, max_vcpu=64, max_memory=64, max_disk_space=128) -> list:\n",
    "    res = []\n",
    "\n",
    "    for i in range(n):\n",
    "        # generate cluster name\n",
    "        cluster_name = generate_cluster_name()\n",
    "        # generate vCPU\n",
    "        vcpu = random.randint(1, max_vcpu)\n",
    "        # generate Memory (GB)\n",
    "        memory = random.randint(1, max_memory)\n",
    "        # generate Disk Space (GB)\n",
    "        disk_space = random.randint(1, max_disk_space)\n",
    "        res.append([cluster_name, vcpu, memory, disk_space])\n",
    "    return np.array(res)\n",
    "\n",
    "def show_clusters(clusters: list):\n",
    "    max_len_name = max([len(cluster[0]) for cluster in clusters]) + 5\n",
    "    print(f\"Cluster Name{' '*(max_len_name-12)}\\tvCPU\\tMemory(GB)\\tDisk Space(GB)\")\n",
    "    for cluster in clusters:\n",
    "        print(f\"{cluster[0]+ ' '*(max_len_name - len(cluster[0]))}\\t{cluster[1]}\\t{cluster[2]}\\t\\t{cluster[3]}\")\n",
    "\n",
    "clusters = generate_cluster(10)\n",
    "show_clusters(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\min \\sum_{i=1}^{n} xy_i $\n",
    "\n",
    "s.t.$ \\sum_{j=1}^{m} w_j x_{ij} \\leq c_i, \\forall i \\in \\{1, \\ldots, n\\} $\n",
    "\n",
    "$ \\sum_{i=1}^{n} x_{ij} = 1, \\forall j \\in \\{1, \\ldots, m\\} $\n",
    "\n",
    "$y_i \\in \\{0, 1\\}, \\forall i \\in \\{1, \\ldots, n\\}$\n",
    "\n",
    "$x_{ij} \\in \\{0, 1\\}, \\forall i \\in \\{1, \\ldots, n\\}, j \\in \\{1, \\ldots, m\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea create a big variable \n",
    "\n",
    "[cluster0, cluster1, ... clusterN, \n",
    "\n",
    "vm0_cluster0, vm0_cluster1, ... vm0_clusterN, \n",
    "\n",
    "vm1_cluster0, vm1_cluster1, ... vm1_clusterN, \n",
    "\n",
    "... \n",
    "\n",
    "vmM_cluster0, vmM_cluster1, ... vmM_clusterN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the relaxed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_relaxed_constraint_A(clusters, vms, constraint_idx):\n",
    "    \"\"\"\n",
    "    A helper function to generate the constraint matrix for a single constraint\n",
    "    \n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "    constraint_idx: int - the index of the constraint to generate the matrix for\n",
    "\n",
    "    Output:\n",
    "    A: np.array(float) - the constraint matrix for the given constraint_idx\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    cluster_constraints = clusters[:, constraint_idx].astype(float)\n",
    "    vm_constraints = vms[:, constraint_idx].astype(float)\n",
    "    n_clusters = len(cluster_constraints)\n",
    "    n_vms = len(vm_constraints)\n",
    "    A = np.zeros((n_clusters, n_clusters + n_clusters*n_vms))\n",
    "    for i in range(n_clusters):\n",
    "        A[i, i] = -cluster_constraints[i]\n",
    "        A[i, n_clusters:][[i + j * n_clusters for j in range(n_clusters)]] = vm_constraints\n",
    "    return A\n",
    "\n",
    "\n",
    "def relaxed_bin_packing(clusters, vms):\n",
    "    \"\"\"\n",
    "    Relaxed big packing problem:\n",
    "    Given a set of clusters and a set of VMs, assign a COEFFICIENT for each VM to a cluster such that\n",
    "    the total resource usage of each cluster does not exceed the capacity of the cluster.\n",
    "    The objective is to minimize the number of clusters used.\n",
    "\n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "\n",
    "    Output:\n",
    "    cluster_assignment: np.array(int) - a list of cluster assignments for each VM\n",
    "    vm_assignment: np.array(float) - a list of coefficients for each VM to each cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # Define sizes\n",
    "    n_cluster = len(clusters)\n",
    "    n_vm = len(vms)\n",
    "    n_constraints = vms.shape[1] - 1 # remove the name column\n",
    "    n_var = n_cluster + n_cluster*n_vm\n",
    "\n",
    "    # Define the objective function\n",
    "    c = np.zeros(n_var)\n",
    "    c[:n_cluster] = 1\n",
    "\n",
    "    # Define the constraints\n",
    "    # constraints on the variables\n",
    "    A = np.zeros((n_var + n_vm, n_var))\n",
    "    A[:n_var] = np.eye(n_var)\n",
    "\n",
    "    # constraints on the coefficients of the VMs\n",
    "    for i in range(n_vm):\n",
    "        A[n_var + i, n_cluster + i*n_cluster:n_cluster + (i+1)*n_cluster] = np.ones(n_cluster)\n",
    "\n",
    "    # constraints on the cluster capacities\n",
    "    for i in range(n_constraints):\n",
    "        A = np.concatenate((A, one_relaxed_constraint_A(clusters, vms, i+1)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster, n_var)\n",
    "\n",
    "    # Define the upper and lower bounds\n",
    "    ub = np.concatenate((np.ones(n_var + n_vm), np.zeros(n_cluster*n_constraints)))\n",
    "    lb = np.concatenate((np.zeros(n_var), np.ones(n_vm), [-np.inf]*(n_cluster*n_constraints)))\n",
    "\n",
    "    # Define the integrality\n",
    "    integrality = np.array([True]*n_cluster + [False]*n_cluster*n_vm)\n",
    "\n",
    "    # Define the constraints as a LinearConstraint object\n",
    "    constraints = LinearConstraint(A, lb, ub)\n",
    "\n",
    "    # Solve the problem\n",
    "    res = milp(c=c, constraints=constraints, integrality=integrality)\n",
    "\n",
    "    # Return the results (cluster assignment, vm assignment)\n",
    "    return res.x[:n_cluster], res.x[n_cluster:].reshape(n_vm, n_cluster)\n",
    "\n",
    "\n",
    "assign_cluster, assign_vm = relaxed_bin_packing(clusters, vms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Name           \tCPU usage (%)\tMem usage (%)\tDisk usage (%)\tAssigned VMs\n",
      "us-west1-Zeta-864      \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-east3-Alpha-238     \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-east1-Iota-619      \t11.67%\t\t73.81%\t\t40.10%\t\t3: FluffyToaster-708, SpicyToaster-434, ZestyPickle-890\n",
      "us-west1-Gamma-943     \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-west1-Zeta-431      \t43.70%\t\t100.00%\t\t100.00%\t\t6: BouncyMuffin-691, SpicyToaster-434, BouncyPenguin-903, ZestyPickle-890, SpicyBanana-557, FluffyMuffin-527\n",
      "us-west2-Gamma-887     \t16.36%\t\t77.27%\t\t77.27%\t\t2: BouncyPenguin-903, WobblySasquatch-961\n",
      "us-east1-Beta-91       \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-west2-Eta-739       \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-west2-Eta-771       \t100.00%\t\t100.00%\t\t86.58%\t\t4: FluffyToaster-708, FluffyPancake-174, BouncyPenguin-903, QuirkyPickle-551\n",
      "us-east2-Eta-567       \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n"
     ]
    }
   ],
   "source": [
    "def pretty_assignment_print(assign_cluster, assign_vm, clusters=clusters, vms=vms):\n",
    "    n_cluster = len(assign_cluster)\n",
    "    n_vm = len(assign_vm)\n",
    "    max_len_cluster = max([len(cluster[0]) for cluster in clusters]) + 5\n",
    "    print(\n",
    "        f\"Cluster Name{' '*(max_len_cluster-12)}\\tCPU usage (%)\\tMem usage (%)\\tDisk usage (%)\\tAssigned VMs\")\n",
    "    for i in range(n_cluster):\n",
    "        assigned_vms = [vms[j][0] for j in range(n_vm) if assign_vm[j][i] > 0]\n",
    "        cpu_usage = sum([float(vms[j][1])*assign_vm[j][i]\n",
    "                        for j in range(n_vm)])\n",
    "        memory_usage = sum([float(vms[j][2])*assign_vm[j][i]\n",
    "                           for j in range(n_vm)])\n",
    "        disk_space_usage = sum(\n",
    "            [float(vms[j][3])*assign_vm[j][i] for j in range(n_vm)])\n",
    "        print(f\"{clusters[i][0] + ' '*(max_len_cluster - len(clusters[i][0]))}\\t{cpu_usage/float(clusters[i][1])*100:.2f}%\\t\\t{memory_usage/float(clusters[i][2])*100:.2f}%\\t\\t{disk_space_usage/float(clusters[i][3])*100:.2f}%\\t\\t{len(assigned_vms)}: {', '.join(assigned_vms)}\")\n",
    "\n",
    "\n",
    "pretty_assignment_print(assign_cluster, assign_vm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_packing(clusters, vms):\n",
    "    \"\"\" \n",
    "    Bin packing problem:\n",
    "    Given a set of clusters and a set of VMs, assign each VM to a cluster such that\n",
    "    the total resource usage of each cluster does not exceed the capacity of the cluster.\n",
    "    \n",
    "    Input:\n",
    "    clusters: np.array(str, float, float, float) - a list of clusters with each row representing a cluster and each column representing a resource\n",
    "    vms: np.array(str, float, float, float) - a list of VMs with each row representing a VM and each column representing a resource\n",
    "\n",
    "    Output:\n",
    "    cluster_assignment: np.array(int) - a list of cluster assignments for each VM\n",
    "    vms_assignment: np.array(int) - a list of VM assignments to each cluster\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    # Define sizes\n",
    "    n_cluster = len(clusters)\n",
    "    n_vm = len(vms)\n",
    "    n_constraints = vms.shape[1] - 1 # remove the name column\n",
    "    n_var = n_cluster + n_cluster*n_vm\n",
    "\n",
    "    # Define the objective function\n",
    "    c = np.zeros(n_var)\n",
    "    c[:n_cluster] = 1\n",
    "\n",
    "    # Define the constraints\n",
    "    # constraints on the variables\n",
    "    A = np.zeros((n_var + n_vm, n_var))\n",
    "    A[:n_var] = np.eye(n_var)\n",
    "\n",
    "    # constraints on the coefficients of the VMs\n",
    "    for i in range(n_vm):\n",
    "        A[n_var + i, n_cluster + i*n_cluster:n_cluster + (i+1)*n_cluster] = np.ones(n_cluster)\n",
    "\n",
    "    # constraints on the cluster capacities\n",
    "    for i in range(n_constraints):\n",
    "        A = np.concatenate((A, one_relaxed_constraint_A(clusters, vms, i+1)))\n",
    "    # A shape = (n_var + n_vm + n_constraints*n_cluster, n_var)\n",
    "\n",
    "    # Define the upper and lower bounds\n",
    "    ub = np.concatenate((np.ones(n_var + n_vm), np.zeros(n_cluster*n_constraints)))\n",
    "    lb = np.concatenate((np.zeros(n_var), np.ones(n_vm), [-np.inf]*(n_cluster*n_constraints)))\n",
    "\n",
    "    # Define the integrality\n",
    "    integrality = np.array([True]*n_var)\n",
    "\n",
    "    # Define the constraints as a LinearConstraint object\n",
    "    constraints = LinearConstraint(A, lb, ub)\n",
    "\n",
    "    # Solve the problem\n",
    "    res = milp(c=c, constraints=constraints, integrality=integrality)\n",
    "\n",
    "    # Return the results (cluster assignment, vm assignment)\n",
    "    return res.x[:n_cluster], res.x[n_cluster:].reshape(n_vm, n_cluster)\n",
    "\n",
    "\n",
    "assign_cluster, assign_vm = bin_packing(clusters, vms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Name           \tCPU usage (%)\tMem usage (%)\tDisk usage (%)\tAssigned VMs\n",
      "us-west1-Zeta-864      \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-east3-Alpha-238     \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-east1-Iota-619      \t27.78%\t\t100.00%\t\t80.49%\t\t3: SpicyToaster-434, QuirkyPickle-551, FluffyMuffin-527\n",
      "us-west1-Gamma-943     \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-west1-Zeta-431      \t27.66%\t\t97.67%\t\t85.07%\t\t3: FluffyPancake-174, BouncyPenguin-903, ZestyPickle-890\n",
      "us-west2-Gamma-887     \t17.86%\t\t66.67%\t\t69.23%\t\t2: SpicyBanana-557, WobblySasquatch-961\n",
      "us-east1-Beta-91       \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-west2-Eta-739       \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n",
      "us-west2-Eta-771       \t80.00%\t\t97.50%\t\t56.76%\t\t2: FluffyToaster-708, BouncyMuffin-691\n",
      "us-east2-Eta-567       \t0.00%\t\t0.00%\t\t0.00%\t\t0: \n"
     ]
    }
   ],
   "source": [
    "pretty_assignment_print(assign_cluster, assign_vm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Affinity rules between some set of VMs\n",
    "\n",
    "some VMs could share a cluster / some others couln't (affinity / anti-affinity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. All servers are partly occupied vs totally empty and all with the same characteristics\n",
    "\n",
    "1 type of server vs multiple types of several type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. VMs could be splitted over several servers\n",
    "\n",
    "VMs could be splitted over several servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Consider VMs families, each family is given a criticity level between 1 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # simple integer programming with SciPY\n",
    "\n",
    "# # define the objective function\n",
    "# c = np.array([1, 1, 0, 0, 0, 0]) # 2 clusters, 2 VMs\n",
    "\n",
    "# # define the constraints\n",
    "# A = np.array([[1, 0,     0, 0, 0, 0],\n",
    "#               [0, 1,     0, 0, 0, 0],\n",
    "#               [0, 0,     1, 0, 0, 0],\n",
    "#               [0, 0,     0, 1, 0, 0],\n",
    "#               [0, 0,     0, 0, 1, 0],\n",
    "#               [0, 0,    0, 0, 0, 1], # n_cluster + n_vm*n_cluster\n",
    "\n",
    "#               [-3, 0,    2, 0, 3, 0],\n",
    "#               [0, -3,    0, 2, 0, 3], # n_cluster\n",
    "\n",
    "#               [0, 0,     1, 1, 0, 0],\n",
    "#               [0, 0,     0, 0, 1, 1]]) # n_vm\n",
    "#             # n_cluster   n_cluster * n_vm\n",
    "\n",
    "# # 0 <= y1 <= 1\n",
    "# # 0 <= y2 <= 1\n",
    "# # 2x00 + 3x01 <= 4y1\n",
    "# # 2x10 + 3x11 <= 5y2\n",
    "# # x00 + x01 <= 1\n",
    "# # x10 <= 1\n",
    "# # x11 <= 1\n",
    "\n",
    "# ub = np.array([1, 1, 1, 1, 1, 1, 0, 0, 1, 1]) # upper bounds\n",
    "# lb = np.array([0, 0, 0, 0, 0, 0, -np.inf, -np.inf, 1, 1]) # lower bounds\n",
    "# # x00+ x01 = 1\n",
    "# # x10 + x11 = 1\n",
    "# #constraints1 = {'type': 'eq', 'fun': lambda x: np.array([x[2] + x[3] - 1, x[4] + x[5] - 1])}\n",
    "# constraints = LinearConstraint(A, lb, ub)\n",
    "\n",
    "# integrality = np.array([True, True, False, False, False, False])\n",
    "\n",
    "# res = milp(c=c, constraints=constraints, integrality=integrality)\n",
    "# res.x\n",
    "\n",
    "\n",
    "\n",
    "# def one_constraints_bin_packing(clusters, vms, constraint_idx):\n",
    "#     cluster_constraints = clusters[:, constraint_idx].astype(float)\n",
    "#     vm_constraints = vms[:, constraint_idx].astype(float)\n",
    "#     n_clusters = len(cluster_constraints)\n",
    "#     n_vms = len(vm_constraints)\n",
    "\n",
    "#     n_var  = n_clusters + n_vms*n_clusters\n",
    "#     c = np.zeros(n_var)\n",
    "#     c[:n_clusters] = 1\n",
    "\n",
    "#     A = np.zeros((n_var + n_clusters + n_vms, n_var))\n",
    "\n",
    "#     A[:n_var] = np.eye(n_var)\n",
    "\n",
    "#     start = n_var\n",
    "#     A[start:start+n_clusters] = one_constraint_A(clusters, vms, constraint_idx)\n",
    "\n",
    "#     start += n_clusters\n",
    "#     for i in range(n_vms):\n",
    "#         A[start + i, n_clusters + i*n_clusters:n_clusters + (i+1)*n_clusters] = np.ones(n_clusters)\n",
    "\n",
    "#     ub =np.concatenate((np.ones(n_var), np.zeros(n_clusters), np.ones(n_vms)))\n",
    "#     lb = np.concatenate((np.zeros(n_var), [-np.inf]*n_clusters, np.ones(n_vms)))\n",
    "\n",
    "#     integrality = np.array([True]*n_clusters + [False]*n_clusters*n_vms)\n",
    "#     constraints = LinearConstraint(A, lb, ub)\n",
    "\n",
    "#     res = milp(c=c, constraints=constraints, integrality=integrality)\n",
    "#     return res.x[:n_clusters], res.x[n_clusters:].reshape(n_vms, n_clusters)\n",
    "\n",
    "# one_constraints_bin_packing(np.array(clusters), np.array(vms), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
